services:
    postgres:
        container_name: postgres_container
        image: postgres
        environment:
            POSTGRES_USER: ${POSTGRES_USER:-postgres}
            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}
            PGDATA: /data/postgres
        volumes:
            - postgres:/data/postgres
        ports:
            - "5432:5432"
        networks:
            - postgres
        restart: unless-stopped
    
    pgadmin:
        container_name: pgadmin_container
        image: dpage/pgadmin4
        environment:
            PGADMIN_DEFAULT_EMAIL: ${PGADMIN_DEFAULT_EMAIL:-pgadmin4@pgadmin.org}
            PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_DEFAULT_PASSWORD:-admin}
            PGADMIN_CONFIG_SERVER_MODE: 'False'
        volumes:
            - pgadmin:/var/lib/pgadmin
        ports:
            - "${PGADMIN_PORT:-5050}:80"
        networks:
            - postgres
        restart: unless-stopped
        logging:
            driver: "none"
    
    llm-chat:
        image: disk0dancer/vllm-arm:0.7.3
        volumes:
            - ~/.cache/huggingface:/root/.cache/huggingface
        entrypoint: python3
        command: -m vllm.entrypoints.openai.api_server --port=5000 --host=0.0.0.0 --model Qwen/Qwen2.5-Coder-0.5B-Instruct --dtype float16  --device cpu --disable-async-output-proc --swap-space 2 --uvicorn-log-level debug --enforce-eager --worker-cls "vllm.worker.cpu_worker.CPUWorker"
        environment:
            - VLLM_TARGET_DEVICE=cpu
            - HF_HUB_OFFLINE=1
            - TRANSFORMERS_OFFLINE=1
            - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-token}
        ports:
            - "5002:5000"
        healthcheck:
            test: [ "CMD", "curl", "-f", "http://0.0.0.0:5000/v1/models" ]
            interval: 30s
            timeout: 5s
            retries: 20
        networks:
            - llm-chat

    llm-completion:
        image: disk0dancer/vllm-arm:0.7.3
        volumes:
            - ~/.cache/huggingface:/root/.cache/huggingface
        entrypoint: python3
        command: -m vllm.entrypoints.openai.api_server --port=5000 --host=0.0.0.0 --model Qwen/Qwen2.5-Coder-0.5B-Instruct --dtype float16  --device cpu --disable-async-output-proc --swap-space 2 --uvicorn-log-level debug --enforce-eager --worker-cls "vllm.worker.cpu_worker.CPUWorker"
        environment:
            - HF_HUB_OFFLINE=1
            - TRANSFORMERS_OFFLINE=1
            - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-token}
        ports:
            - "5001:5000"
        healthcheck:
            test: [ "CMD", "curl", "-f", "http://0.0.0.0:5000/v1/models" ]
            interval: 30s
            timeout: 5s
            retries: 20
        networks:
            - llm-completion

    backend:
        image: disk0dancer/copilot-api:latest
        ports:
            - 8000:8000
        environment:
            - LLM_URL=http://0.0.0.0:5001
            - LLM_CHAT_URL=http://0.0.0.0:5002
            - POSTGRES_CONN_URL=postgresql+asyncpg://postgres:postgres@127.0.0.1:5432/postgres
        healthcheck:
            test: [ "CMD", "curl", "-f", "http://0.0.0.0:8000/health" ]
            interval: 30s
            timeout: 5s
            retries: 20
        networks:
            - postgres
            - llm-chat
            - llm-completion
        
        

networks:
    postgres:
        driver: bridge
    llm-chat:
        driver: bridge
    llm-completion:
        driver: bridge

volumes:
    postgres:
    pgadmin:
    llm-chat:
    llm-completion:
